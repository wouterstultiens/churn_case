{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7n4uiXhvgg_"
   },
   "source": [
    "# Customer churn with a classifcation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZeMmb2KvghB"
   },
   "source": [
    "**Content:**\n",
    "1. [Install packages and load data](#1)\n",
    "1. [Data Exploration](#2)\n",
    "1. [Data Preparation](#3)\n",
    "1. [Feature Engineering](#4)\n",
    "1. [Multivariate Analysis ](#5)\n",
    "1. [Split into train- and testset](#6)\n",
    "1. [Train and validate models](#7)\n",
    "1. [K-fold cross validation](#8)\n",
    "1. [Advanced Models I: LightGBM](#9)\n",
    "1. [Advanced Models II: CatBoost](#10)\n",
    "\n",
    "The code guides you through the process, but contains a number of '...' and '???' bits that you can fill in yourself. Of course you are also free to add other functions and steps to further improve the churn predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60LqrovvvghB"
   },
   "source": [
    "<a id=\"1\"></a> \n",
    "\n",
    "\n",
    "## 1. Install packages and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5G35K6YvghC"
   },
   "outputs": [],
   "source": [
    "# a) Install packages\n",
    "import pandas as pd       # 'as' := we abbreviate the package for common use\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "import datetime\n",
    "import collections\n",
    "import scipy.stats as stats                             # Fit of distribution plot\n",
    "from sklearn.model_selection import train_test_split    # Split train-/testset     \n",
    "from sklearn.tree import DecisionTreeClassifier         # Modeling CART Decision Tree  \n",
    "from sklearn import metrics                             # Performance metrics\n",
    "from sklearn.metrics import accuracy_score              # Accuracy of a model\n",
    "from sklearn.metrics import classification_report       # Performance report of a classification model\n",
    "from sklearn.metrics import f1_score,average_precision_score                    # f1 score of model\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler,TomekLinks\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "import graphviz as gv                                   # Needed to graph Decision Tree\n",
    "import pydotplus                                        # Needed to graph Decision Tree\n",
    "from IPython.display import Image                       # Needed to graph Decision Tree\n",
    "from six import StringIO                                # Needed to graph Decision Tree\n",
    "from sklearn.tree import export_graphviz                # Needed to graph Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier     # Modeling Random Forest\n",
    "from sklearn.ensemble import AdaBoostClassifier         # Modeling AdaBoost \n",
    "from sklearn.ensemble import GradientBoostingClassifier # Modeling XGBoost\n",
    "from sklearn.model_selection import KFold               # Cross-validation using stratified K-fold\n",
    "from sklearn.model_selection import RandomizedSearchCV  # Randomized searching through a parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64BR7WTrvghF"
   },
   "outputs": [],
   "source": [
    "# b) Load data\n",
    "\n",
    "inputdata = pd.read_csv(\"Churn_Modelling_undersampled.csv\")\n",
    "\n",
    "#    Get an overview of the data\n",
    "inputdata.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVLYdc-lvghI"
   },
   "source": [
    "<a id=\"2\"></a> \n",
    "\n",
    "\n",
    "## 2. Data Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhy5wkBdvghI",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# a) Get an overview of the data\n",
    "#    Get the number of rows and columns\n",
    "print('(nrow, ncol):', inputdata.shape)     \n",
    "\n",
    "#    Show a brief summary of the numeric variables\n",
    "inputdata.describe()                        # min/max, count, mean, std and percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "osKARXKVvghL",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# b) Check data type of each variable\n",
    "print(pd.DataFrame(inputdata.dtypes, columns=['Datatype']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GcAE3k-YvghN",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# c) Get an overview of the NULLS in the dataset\n",
    "nulls = pd.DataFrame(inputdata.isnull().sum(), columns=['# NULLS'])        # Number of NULLS \n",
    "\n",
    "lst={}                                                                     # Number of NULLS as a percentage\n",
    "for col in inputdata.columns:                                       \n",
    "    lst[col]=np.sum(inputdata.loc[:,col].isnull())/len(inputdata.loc[:,col])\n",
    "percNulls = pd.DataFrame(pd.Series(lst), columns=['% NULLS'])\n",
    "\n",
    "print(pd.concat([nulls, percNulls], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vI4livbmvghQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# analyze target variable\n",
    "target = '???'\n",
    "\n",
    "inputdata[target].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwVY5K3VvghS"
   },
   "outputs": [],
   "source": [
    "# e) Analyze categorical variables\n",
    "inputdata['...'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLtBIolHvghV"
   },
   "outputs": [],
   "source": [
    "# f) Analyze distribution of continuous variable\n",
    "variable_analyzed = '???'\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.hist((inputdata[variable_analyzed]), bins=250, color = 'blue', edgecolor = 'blue')\n",
    "plt.title('Distribution of {}'.format(variable_analyzed))\n",
    "plt.xlabel(variable_analyzed)\n",
    "plt.ylabel('#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17_-KkNOvghY"
   },
   "source": [
    "<a id=\"3\"></a> \n",
    "\n",
    "\n",
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1mhgoJzvghY",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(inputdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QyjBz9Bbvghc"
   },
   "outputs": [],
   "source": [
    "# a) Drop outliers (where features have impossibly high or impossibly low values)\n",
    "\n",
    "inputdata = inputdata[~(inputdata['Age']>=.....)] # What would be a logical cut-off?\n",
    "inputdata = inputdata[~(inputdata['???']<.....)] # What other features have values that shouldn't exist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubFiwQ1Gvghe"
   },
   "outputs": [],
   "source": [
    "# b) Deal with the missing data. What is logical to fill the missing data with?\n",
    "inputdata.NumOfProducts = inputdata.NumOfProducts.fillna(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tQk-ZMDvghj"
   },
   "source": [
    "<a id=\"4\"></a> \n",
    "\n",
    "\n",
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CqEn3tfqvghj"
   },
   "outputs": [],
   "source": [
    "# a) Creating new variables\n",
    "\n",
    "#inputdata['...'][<condition> = '...'\n",
    "#inputdata['...'] = inputdata['...'] * inputdata['...']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9BOBFFWvghm"
   },
   "outputs": [],
   "source": [
    "# b) Dummmify the categorical variables\n",
    "categoricals = ['...' \n",
    "               ]\n",
    "inputdata = pd.get_dummies(inputdata, columns=categoricals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXskV0ZBvgho"
   },
   "source": [
    "<a id=\"5\"></a> \n",
    "\n",
    "\n",
    "## 5. Multivariate Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbWDaqM8vgho"
   },
   "outputs": [],
   "source": [
    "inputdata.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLtKsXULvghr"
   },
   "outputs": [],
   "source": [
    "# a) Create barplot to see the relation between the dummy-variables and target variable\n",
    "dummies = ['...'\n",
    "          ]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for i, column in enumerate(dummies):\n",
    "    plt.subplot(math.ceil(len(dummies)/3), 3, i+1)\n",
    "    sns.barplot(x=column, y=target, data=inputdata, palette='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IpT3rceGvght"
   },
   "outputs": [],
   "source": [
    "#  b) Show correlation matrix to look for mutual correlations\n",
    "columns = ['...'\n",
    "          ]\n",
    "\n",
    "correlation = inputdata[columns]\n",
    "corrmat = correlation.corr().round(2)\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True, annot=True, cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l61PmnG0vghv"
   },
   "source": [
    "<a id=\"6\"></a> \n",
    "\n",
    "\n",
    "## 6. Split into train- and testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnufLq6Evghv"
   },
   "outputs": [],
   "source": [
    "# a) Split the data. If you do not know what to fill in, google the function (add scikit in the search)\n",
    "data_train, data_test  = train_test_split(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) convert all column names to strings\n",
    "data_train.columns = data_train.columns.astype(str)\n",
    "data_test.columns = data_test.columns.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqwjxTi6vghy"
   },
   "source": [
    "<a id=\"7\"></a> \n",
    "\n",
    "\n",
    "## 7. Train and validate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPSLPzt5vghy"
   },
   "source": [
    "<a id=\"5a\"></a> \n",
    "### A) Decision Tree CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QUxIs1osvghy"
   },
   "outputs": [],
   "source": [
    "# get all variable names\n",
    "data_train.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mnvY2I77vgh0"
   },
   "outputs": [],
   "source": [
    "# Define X and y \n",
    "X_variables = ['...']           # Adjust to your needs\n",
    "y_variable = '...'\n",
    "\n",
    "X_train = data_train.loc[:, X_variables]\n",
    "y_train = data_train[y_variable]\n",
    "X_test = data_test.loc[:, X_variables]\n",
    "y_test = data_test[y_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mST_qEBvgh2"
   },
   "outputs": [],
   "source": [
    "# a) Set model parameters \n",
    "#    Note: if Min_bucket is too large, the tree might not branch, if too small, the tree might get to big to interpret\n",
    "Min_num_splits = ...                            # Minimum number of items to split\n",
    "Min_bucket     = ...               # Minimum number of items per bucket\n",
    "Max_depth      = ...        # Maximum depth of final tree (nr of levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KEqjfOlvgh4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# b) Estimate the model \n",
    "mytree = DecisionTreeClassifier(max_depth=Max_depth\n",
    "                                ,min_samples_split=Min_num_splits\n",
    "                                ,min_samples_leaf=Min_bucket\n",
    "                                ,criterion=\"gini\"              \n",
    "                                ,splitter=\"best\"\n",
    "                                ,random_state=random.seed()\n",
    "                                )\n",
    "\n",
    "mytree.fit(X_train, y_train)     # Fit the model over the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "buIrqWD-vgh7"
   },
   "outputs": [],
   "source": [
    "# c) Create predictions for the test set\n",
    "preds_proba = mytree.predict_proba(...)\n",
    "preds = mytree.predict(...)   # Cut-off point equals 0.5\n",
    "\n",
    "#    Show the first 5 lines of the prediction probabilities and corresponding prediction\n",
    "pd.concat([pd.DataFrame(preds_proba, columns=[\"Prob. 0\", \"Prob. 1\"]), pd.DataFrame(preds, columns=[\"Prediction\"])], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCh-g-qcvgh9"
   },
   "outputs": [],
   "source": [
    "#    Calculate the optimal cut-off point\n",
    "cost_TP = ...\n",
    "cost_TN = ...\n",
    "cost_FP = ...\n",
    "cost_FN = ...\n",
    "total_cost = math.inf\n",
    "\n",
    "for i in np.linspace(0,1,100,endpoint=False):\n",
    "    y_pred = (preds_proba[:,1]>i).astype('int')\n",
    "    results = metrics.confusion_matrix(y_pred,y_test)\n",
    "    TN = results[0][0]\n",
    "    FN = results[0][1]\n",
    "    FP = results[1][0]\n",
    "    TP = results[1][1]\n",
    "    \n",
    "    # Calculate cutoff-point\n",
    "    cost = TN*cost_TN + TP*cost_TP + FP*cost_FP + FN*cost_FN\n",
    "    total_cost = min(total_cost,cost)\n",
    "    if(total_cost == cost):\n",
    "        opt_cutoff = i\n",
    "        \n",
    "print('Optimal cut-off:', opt_cutoff)\n",
    "\n",
    "#    Create predictions for the test set according to optimal cutoff point\n",
    "preds = (preds_proba[:,1] > opt_cutoff).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NhfvNfZ6vgiA"
   },
   "outputs": [],
   "source": [
    "#    Plot tpr vs 1-fpr\n",
    "fpr, tpr, t = metrics.roc_curve(y_test, preds_proba[:,1])\n",
    "i = np.arange(len(tpr)) # index for df\n",
    "roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i)\n",
    "                    ,'1-fpr' : pd.Series(1-fpr, index = i)\n",
    "                    ,'tf' : pd.Series(tpr - (1-fpr), index = i)\n",
    "                    ,'thresholds' : pd.Series(t, index = i)})\n",
    "print(roc.loc[(roc.tf-0).abs().argsort()[:1]])\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(roc['tpr'])\n",
    "plt.plot(roc['1-fpr'], color = 'red')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('1-False Positive Rate')\n",
    "ax.set_xticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJu2EC2qvgiD"
   },
   "outputs": [],
   "source": [
    "# d) Evaluate results\n",
    "#    i. Create confusion matrix\n",
    "print(pd.crosstab(..., ...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7JbjohDqvgiE"
   },
   "outputs": [],
   "source": [
    "#    ii. Create classification report\n",
    "print(classification_report(..., ...))\n",
    "f1_DT = f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUnQVOSYvgiG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#    iii. Get the feature importances of the tree\n",
    "importances = mytree.feature_importances_ \n",
    "std = np.std([mytree.feature_importances_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "importances_features = []\n",
    "print(\"Feature ranking:\")                    # Print the feature ranking\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"Feature %d (%s) %f\" % (indices[f], X_variables[indices[f]], importances[indices[f]]))\n",
    "    importances_features.append(X_variables[indices[f]])\n",
    "\n",
    "plt.figure(figsize=(7.5,5))\n",
    "plt.figure()                                 # Plot the feature importances \n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.title(\"Feature importances\")\n",
    "plt.ylabel(\"Importance in terms of decreasing the weighted impurity\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.xticks(range(X_train.shape[1]), importances_features, rotation = 30)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSjtCxqevgiK"
   },
   "outputs": [],
   "source": [
    "#    iv. Create ROC curve\n",
    "fpr, tpr, t = metrics.roc_curve(y_test, preds_proba[:,1])\n",
    "\n",
    "#     v. Calculate AUC\n",
    "CART_roc_auc_tree = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')      # Plot results\n",
    "plt.plot(fpr, tpr, lw=2, alpha=0.3, label='Mean ROC Decision Tree CART (AUC = %0.2f)' % (CART_roc_auc_tree))\n",
    "plt.title('ROC curve')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_XSpEMLvgiN"
   },
   "outputs": [],
   "source": [
    "# e) Visualize Decision Tree\n",
    "dot_data = StringIO()\n",
    "export_graphviz(mytree, out_file=dot_data,           # mytree := name of your decision treee\n",
    "                filled=True, rounded=True,\n",
    "                feature_names=X_variables,\n",
    "                special_characters=True)\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mK12aXv4vgiO"
   },
   "source": [
    "<a id=\"5c\"></a> \n",
    "### B) Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7-5d6HhvgiP"
   },
   "outputs": [],
   "source": [
    "# Define X and y \n",
    "X_variables = ['...']  # Adjust to your needs\n",
    "\n",
    "X_train = data_train.loc[:, X_variables]\n",
    "y_train = data_train[y_variable]\n",
    "X_test = data_test.loc[:, X_variables]\n",
    "y_test = data_test[y_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ubke1fo5vgiQ"
   },
   "outputs": [],
   "source": [
    "# a) Set model parameters \n",
    "#     Note: You can tweak the size of your forest by changing 'N_trees', but note computation time increases with size\n",
    "#     Note: if Min_bucket is too large, the trees might not branch\n",
    "N_trees        = ...                           # Number of trees that are estimated\n",
    "Min_num_splits = ...                            # Minimum number of items to split    \n",
    "Min_bucket     = math.floor(Min_num_splits/3)  # Minimum number of items per bucket\n",
    "Max_depth      = ...                            # Maximum depth of each tree (nr of levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpMKtL-8vgiS"
   },
   "outputs": [],
   "source": [
    "# b) Estimate the model\n",
    "forest = RandomForestClassifier(n_estimators = N_trees\n",
    "                                ,criterion = \"gini\"            \n",
    "                                ,max_depth = Max_depth\n",
    "                                ,min_samples_split = Min_num_splits\n",
    "                                ,min_samples_leaf = Min_bucket\n",
    "                                ,random_state = random.seed()\n",
    "                                )\n",
    "\n",
    "forest.fit(X_train, y_train)   # Fit the model over the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lW7QI7xvgiU"
   },
   "outputs": [],
   "source": [
    "# c) Create predictions for the test set\n",
    "preds_proba = forest.predict_proba(...)\n",
    "preds = forest.predict(...)   # Cut-off point equals 0.5\n",
    "\n",
    "#    Show the first 5 lines of the prediction probabilities and corresponding prediction\n",
    "pd.concat([pd.DataFrame(preds_proba, columns=[\"Prob. 0\", \"Prob. 1\"]), pd.DataFrame(preds, columns=[\"Prediction\"])], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DU0-bdJ8vgiW"
   },
   "outputs": [],
   "source": [
    "# d) Evaluate results\n",
    "#    i. Create confusion matrix\n",
    "print(pd.crosstab(..., ...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1APmKrPvgiY",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#    ii. Create classification report\n",
    "print(classification_report(..., ...))\n",
    "f1_RF = f1_score(..., ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvEtREjbvgiZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#    iii. Get the feature importances of the forest\n",
    "importances = forest.feature_importances_ \n",
    "std = np.std([forest.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "importances_features = []\n",
    "print(\"Feature ranking:\")                    # Print the feature ranking\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"Feature %d (%s) %f\" % (indices[f], X_variables[indices[f]], importances[indices[f]]))\n",
    "    importances_features.append(X_variables[indices[f]])\n",
    "\n",
    "plt.figure(figsize=(7.5,5))\n",
    "plt.figure()                                 # Plot the feature importances \n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.title(\"Feature importances\")\n",
    "plt.ylabel(\"Importance in terms of decreasing the weighted impurity\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.xticks(range(X_train.shape[1]), importances_features, rotation = 30)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGuzuI2Ovgib",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#    iv. Create ROC curve\n",
    "fpr, tpr, t = metrics.roc_curve(y_test, preds_proba[:,1])\n",
    "\n",
    "#     v. Calculate AUC\n",
    "RF_roc_auc_tree = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')      # Plot results\n",
    "plt.plot(fpr, tpr, lw=2, alpha=0.3, label='Mean ROC Decision Tree RF (AUC = %0.2f)' % (RF_roc_auc_tree))\n",
    "plt.title('ROC curve')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PaLjQD69vgid"
   },
   "source": [
    "<a id=\"5d\"></a> \n",
    "### C) ADABOOST (Adaptive Boosting Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oogRNjjfvgie"
   },
   "outputs": [],
   "source": [
    "# Define X and y \n",
    "X_variables = ['...']   # Adjust to your needs\n",
    "\n",
    "X_train = data_train.loc[:, X_variables]\n",
    "y_train = data_train[y_variable]\n",
    "X_test = data_test.loc[:, X_variables]\n",
    "y_test = data_test[y_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oFJ-34_4vgig"
   },
   "outputs": [],
   "source": [
    "# a) Set model parameters \n",
    "#     Note: You can tweak the size of your boost by changing 'N_trees', but note computation time increases with size\n",
    "#     Note: if Min_bucket is too large, the trees might not branch\n",
    "N_trees        = ...                          # Number of trees that are estimated\n",
    "Min_num_splits = ...                            # Minimum number of items to split    \n",
    "Min_bucket     = math.floor(Min_num_splits/3)  # Minimum number of items per bucket\n",
    "Max_depth      = ...                             # Maximum depth of each tree (nr of levels)\n",
    "Learning_rate  = ...                           # The learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1xIvMkCvgii"
   },
   "outputs": [],
   "source": [
    "# b) Estimate model\n",
    "adaptboost = AdaBoostClassifier(n_estimators=N_trees\n",
    "                                ,base_estimator=DecisionTreeClassifier(max_depth = Max_depth\n",
    "                                                                       ,min_samples_split = Min_num_splits\n",
    "                                                                       ,min_samples_leaf = Min_bucket\n",
    "                                                                       ,criterion = \"gini\"              \n",
    "                                                                       ,splitter = \"best\"\n",
    "                                                                       )\n",
    "                                ,learning_rate=Learning_rate\n",
    "                               )\n",
    "\n",
    "adaptboost.fit(X_train, y_train)      # Fit the model over the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3g4utsNDvgik"
   },
   "outputs": [],
   "source": [
    "# c) Create predictions for the test set\n",
    "preds_proba = adaptboost.predict_proba(...)\n",
    "preds = adaptboost.predict(...)   # Cut-off point equals 0.5\n",
    "\n",
    "#    Show the first 5 lines of the prediction probabilities and corresponding prediction\n",
    "pd.concat([pd.DataFrame(preds_proba, columns=[\"Prob. 0\", \"Prob. 1\"]), pd.DataFrame(preds, columns=[\"Prediction\"])], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-Yr1aQXvgim"
   },
   "outputs": [],
   "source": [
    "# d) Evaluate results\n",
    "#    i. Create confusion matrix\n",
    "print(pd.crosstab(..., ...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Khodd_envgio"
   },
   "outputs": [],
   "source": [
    "#    ii. Create classification report\n",
    "print(classification_report(..., ...))\n",
    "f1_ADA = f1_score(..., ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYSxPcTUvgiq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#    iii. Get the feature importances of the Adaboost\n",
    "importances = adaptboost.feature_importances_ \n",
    "std = np.std([adaptboost.feature_importances_ for tree in adaptboost.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "importances_features = []\n",
    "print(\"Feature ranking:\")                    # Print the feature ranking\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"Feature %d (%s) %f\" % (indices[f], X_variables[indices[f]], importances[indices[f]]))\n",
    "    importances_features.append(X_variables[indices[f]])\n",
    "\n",
    "plt.figure(figsize=(7.5,5))\n",
    "plt.figure()                                 # Plot the feature importances \n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.title(\"Feature importances\")\n",
    "plt.ylabel(\"Importance in terms of decreasing the weighted impurity\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.xticks(range(X_train.shape[1]), importances_features, rotation = 30)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0tGEu_4vgis",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#    iv. Create ROC curve\n",
    "fpr, tpr, t = metrics.roc_curve(y_test, preds_proba[:,1])\n",
    "\n",
    "#     v. Calculate AUC\n",
    "ADA_roc_auc_tree = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')      # Plot results\n",
    "plt.plot(fpr, tpr, lw=2, alpha=0.3, label='Mean ROC Decision Tree ADABOOST (AUC = %0.2f)' % (ADA_roc_auc_tree))\n",
    "plt.title('ROC curve')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0bmfRwNvvgiu",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# e) Plot error with respect to number of estimators (trees)\n",
    "trained_adaptboost = adaptboost.fit(X_train, y_train)  \n",
    "\n",
    "real_test_errors = []\n",
    "for real_test_predict in trained_adaptboost.staged_predict(X_test):\n",
    "    real_test_errors.append(1. - accuracy_score(real_test_predict, np.ravel(y_test)))\n",
    "n_trees_real = len(trained_adaptboost)\n",
    "real_estimator_errors = trained_adaptboost.estimator_errors_[:n_trees_real]\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.plot(range(1, n_trees_real + 1),\n",
    "         real_test_errors, c='black',\n",
    "         linestyle='dashed')\n",
    "plt.ylim(min(real_test_errors), max(real_test_errors)+0.1)\n",
    "plt.title('Error with respect to the number of trees')\n",
    "plt.ylabel('Test Error')\n",
    "plt.xlabel('Number of estimators')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KL8wX6QLvgiw"
   },
   "source": [
    "<a id=\"5e\"></a> \n",
    "### D) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hidASLvbvgiw"
   },
   "outputs": [],
   "source": [
    "# Define X and y \n",
    "X_variables = ['...']   # Adjust to your needs\n",
    "\n",
    "X_train = data_train.loc[:, X_variables]\n",
    "y_train = data_train[y_variable]\n",
    "X_test = data_test.loc[:, X_variables]\n",
    "y_test = data_test[y_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0k-fgB9Qvgiy"
   },
   "outputs": [],
   "source": [
    "# a) Set model parameters \n",
    "N_trees        = ...        # Number of trees that are estimated\n",
    "Max_depth      = ...        # Maximum depth of each tree (nr of levels)\n",
    "Learning_rate  = ...        # The learning rate ('eta')\n",
    "Min_bucket     = ...        # Minimum number of items per bucket\n",
    "Subsample      = ...        # Subsample ratio of the training instance\n",
    "Verbose        = ...        # Whether to print messages while running boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bz-3Jcd6vgi0"
   },
   "outputs": [],
   "source": [
    "# b) Estimate model\n",
    "XGB = GradientBoostingClassifier( random_state=12,\n",
    "     n_estimators=N_trees\n",
    "                         ,max_depth=Max_depth \n",
    "                         ,learning_rate=Learning_rate\n",
    "                         ,min_samples_leaf=Min_bucket\n",
    "                         ,subsample=Subsample\n",
    "                         ,verbose=Verbose\n",
    "                      )\n",
    "XGB.fit(X_train, y_train)      # Fit the model over the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZ-U8RO9vgi4"
   },
   "outputs": [],
   "source": [
    "# c) Create predictions for the test set\n",
    "preds_proba = XGB.predict_proba(...)\n",
    "preds = XGB.predict(...)   # Cut-off point equals 0.5\n",
    "\n",
    "#    Show the first 5 lines of the prediction probabilities and corresponding prediction\n",
    "#pd.concat([pd.DataFrame(preds_proba, columns=[\"Prob. 0\", \"Prob. 1\"]), pd.DataFrame(preds, columns=[\"Prediction\"])], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7arZGfXvgi5"
   },
   "outputs": [],
   "source": [
    "# d) Evaluate results\n",
    "#    i. Create confusion matrix\n",
    "print(pd.crosstab(..., ...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_-5Lreuvgi7"
   },
   "outputs": [],
   "source": [
    "#    ii. Create classification report\n",
    "print(classification_report(..., ...))\n",
    "f1_XGB = f1_score(..., ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjVKXvVHvgi9"
   },
   "outputs": [],
   "source": [
    "#    iii. Get the feature importances of the XGBoost\n",
    "importances = XGB.feature_importances_ \n",
    "std = np.std([XGB.feature_importances_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "importances_features = []\n",
    "print(\"Feature ranking:\")                    # Print the feature ranking\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"Feature %d (%s) %f\" % (indices[f], X_variables[indices[f]], importances[indices[f]]))\n",
    "    importances_features.append(X_variables[indices[f]])\n",
    "\n",
    "plt.figure(figsize=(7.5,5))\n",
    "plt.figure()                                 # Plot the feature importances \n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.title(\"Feature importances\")\n",
    "plt.ylabel(\"Importance in terms of decreasing the weighted impurity\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.xticks(range(X_train.shape[1]), importances_features, rotation = 30)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJNyuCQlvgi-"
   },
   "outputs": [],
   "source": [
    "# Create ROC curve\n",
    "fpr, tpr, t = metrics.roc_curve(y_test, preds_proba[:,1])\n",
    "\n",
    "# Calculate AUC\n",
    "XGB_roc_auc_tree = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')      # Plot results\n",
    "plt.plot(fpr, tpr, lw=2, alpha=0.3, label='Mean ROC Decision Tree XGBoost (AUC = %0.2f)' % (XGB_roc_auc_tree))\n",
    "plt.title('ROC curve')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbBrLyX2vgjB"
   },
   "source": [
    "### Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ysRYMi6vgjC"
   },
   "outputs": [],
   "source": [
    "print('AUC Decision Tree:', CART_roc_auc_tree)\n",
    "print('AUC Random Forest:', RF_roc_auc_tree)\n",
    "print('AUC Adaptive Boosting:', ADA_roc_auc_tree)\n",
    "print('AUC XGBoost:', roc_auc_xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5y6BAs58vgjF"
   },
   "source": [
    "<a id=\"8\"></a> \n",
    "\n",
    "\n",
    "## 8. K-fold cross validation\n",
    "\n",
    "The code below iterates through several data balancing methods and several (randomly selected) hyperparameter configurations for each of the four model techniques. <br>\n",
    "\n",
    "The code below uses a Random Search to save time. However, you can also replace it by a full Grid Search to find even better results! See https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGOrmBgjvgjF"
   },
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X_variables = ['...', '...'] # Adjust to your choice\n",
    "y_variable = 'Exited'\n",
    "\n",
    "X_train = data_train.loc[:, X_variables]\n",
    "y_train = data_train[y_variable]\n",
    "X_test = data_test.loc[:, X_variables]\n",
    "y_test = data_test[y_variable]\n",
    "\n",
    "# Sampling methods\n",
    "desiredPercentage = ??? # Decide the percentage that you want in over/under sampling\n",
    "desiredFraction = desiredPercentage/(1-desiredPercentage)\n",
    "\n",
    "ranOS = RandomOverSampler(sampling_strategy=desiredFraction, random_state=1) # Oversampling\n",
    "ranUS = RandomUnderSampler(sampling_strategy=desiredFraction, random_state=1) # Undersampling\n",
    "smt = SMOTE(k_neighbors=2) # SMOTE (bonus: tweak the number of neighbors to maximize results)\n",
    "TL = TomekLinks('not majority') # TomekLinks\n",
    "\n",
    "sampling_methods=[None, ranOS, ranUS, smt, TL]\n",
    "sampling_method_names=['None', 'Oversampling', 'Undersampling', 'SMOTe', 'Tomek Links']\n",
    "\n",
    "# Define parameter grid. Note: some parameters apply to all model techniques, some only to one or some of them.\n",
    "# Fill in appropriate values at the ... yourself.\n",
    "# If you want some ideas for what values might work, you can look up the documentation or other examples online!\n",
    "criterion         = [\"gini\"]\n",
    "learning_rate     = [0.05, 0.1, 0.2, 0.5, 1.0]\n",
    "max_depth         = [...]\n",
    "max_features      = [None, 'sqrt', 'log2', 0.5, 0.2, ...]\n",
    "min_samples_leaf  = [...]\n",
    "min_samples_split = [...]\n",
    "n_estimators      = [...]\n",
    "splitter          = [\"best\"]\n",
    "subsample         = [...]\n",
    "\n",
    "n_iterations = 2 # Number of iterations to use in each random search.\n",
    "# Increasing this value will most likely increase model performance, but certainly also increase the time it takes!\n",
    "\n",
    "aucs = pd.DataFrame(index=range(0, len(sampling_methods)), columns=['Sampling method', 'Decision Tree','Random Forest','Adaboost','XGBoost'])\n",
    "for i in range(len(sampling_methods)):\n",
    "    \n",
    "    j='Sampling method'\n",
    "    sampling_method = sampling_methods[i]\n",
    "    sampling_method_name = sampling_method_names[i]\n",
    "    if sampling_method == None:\n",
    "        X_train_balanced, y_train_balanced = X_train, y_train\n",
    "    else:\n",
    "        X_train_balanced, y_train_balanced = sampling_method.fit_resample(X_train, y_train) # Use sampling method\n",
    "    aucs.loc[i,j] = sampling_method_name\n",
    "\n",
    "    # a) Decision Tree CART\n",
    "    j='Decision Tree'\n",
    "    print(sampling_method_name, '-', j)\n",
    "    dt_params = dict(\n",
    "        criterion         = criterion         ,\n",
    "        max_depth         = max_depth         ,\n",
    "        max_features      = max_features      ,\n",
    "        min_samples_leaf  = min_samples_leaf  ,\n",
    "        min_samples_split = min_samples_split ,\n",
    "        splitter          = splitter          \n",
    "    )\n",
    "    dt_search = RandomizedSearchCV(DecisionTreeClassifier(), dt_params, n_iter=n_iterations, verbose=False)\n",
    "    dt_search = dt_search.fit(X_train_balanced, y_train_balanced)\n",
    "    dt_model = dt_search.best_estimator_\n",
    "    preds_proba = dt_model.predict_proba(X_test)\n",
    "    aucs.loc[i,j] = average_precision_score(y_test, preds_proba[:,1])           # Calculate AP\n",
    "    \n",
    "    # b) Random Forest\n",
    "    j='Random Forest'\n",
    "    print(sampling_method_name, '-', j)\n",
    "    rf_params = dict(\n",
    "        criterion         = criterion         ,\n",
    "        max_depth         = max_depth         ,\n",
    "        max_features      = max_features      ,\n",
    "        min_samples_leaf  = min_samples_leaf  ,\n",
    "        min_samples_split = min_samples_split ,\n",
    "        n_estimators      = n_estimators      \n",
    "    )\n",
    "    rf_search = RandomizedSearchCV(RandomForestClassifier(), rf_params, n_iter=n_iterations, verbose=False)\n",
    "    rf_search = rf_search.fit(X_train_balanced, y_train_balanced)\n",
    "    rf_model = rf_search.best_estimator_\n",
    "    preds_proba = rf_model.predict_proba(X_test)\n",
    "    aucs.loc[i,j] = average_precision_score(y_test, preds_proba[:,1])           # Calculate AP\n",
    "    \n",
    "    # c) Adaboost\n",
    "    j='Adaboost'\n",
    "    print(sampling_method_name, '-', j)\n",
    "    ada_params = dict(\n",
    "        base_estimator__criterion         = criterion         ,\n",
    "        learning_rate                     = learning_rate     ,\n",
    "        base_estimator__max_depth         = max_depth         ,\n",
    "        base_estimator__max_features      = max_features      ,\n",
    "        base_estimator__min_samples_leaf  = min_samples_leaf  ,\n",
    "        base_estimator__min_samples_split = min_samples_split ,\n",
    "        n_estimators                      = n_estimators      ,\n",
    "        base_estimator__splitter          = splitter          \n",
    "    )\n",
    "    ada_search = RandomizedSearchCV(AdaBoostClassifier(base_estimator = DecisionTreeClassifier()), ada_params, n_iter=n_iterations, verbose=False)\n",
    "    ada_search = ada_search.fit(X_train_balanced, y_train_balanced)\n",
    "    ada_model = ada_search.best_estimator_\n",
    "    preds_proba = ada_model.predict_proba(X_test)\n",
    "    aucs.loc[i,j] = metrics.auc(fpr, tpr)           # Calculate AUC\n",
    "    \n",
    "    # d) XGBoost\n",
    "    j='XGBoost'\n",
    "    print(sampling_method_name, '-', j)\n",
    "    xgb_params = dict(\n",
    "        learning_rate     = learning_rate     ,\n",
    "        max_depth         = max_depth         ,\n",
    "        max_features      = max_features      ,\n",
    "        min_samples_leaf  = min_samples_leaf  ,\n",
    "        min_samples_split = min_samples_split ,\n",
    "        n_estimators      = n_estimators      ,\n",
    "        subsample         = subsample         \n",
    "    )\n",
    "    xgb_search = RandomizedSearchCV(GradientBoostingClassifier(), xgb_params, n_iter=n_iterations, verbose=False)\n",
    "    xgb_search = xgb_search.fit(X_train_balanced, y_train_balanced)\n",
    "    xgb_model = xgb_search.best_estimator_\n",
    "    preds_proba = xgb_model.predict_proba(X_test)\n",
    "    aucs.loc[i,j] = metrics.auc(fpr, tpr)           # Calculate AUC\n",
    "\n",
    "aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXXU3kmzvgjI"
   },
   "outputs": [],
   "source": [
    "# Get feature importances from your model of choice\n",
    "model = ... # Choose between dt_model, rf_model, ada_model, xgb_model\n",
    "\n",
    "importances = model.feature_importances_ \n",
    "std = np.std([importances], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "importances_features = []\n",
    "print(\"Feature ranking:\")                    # Print the feature ranking\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"Feature %d (%s) %f\" % (indices[f], X_variables[indices[f]], importances[indices[f]]))\n",
    "    importances_features.append(X_variables[indices[f]])\n",
    "\n",
    "plt.figure(figsize=(7.5,5))\n",
    "plt.figure()                                 # Plot the feature importances \n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.title(\"Feature importances\")\n",
    "plt.ylabel(\"Importance in terms of decreasing the weighted impurity\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.xticks(range(X_train.shape[1]), importances_features, rotation = 30)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a> \n",
    "\n",
    "\n",
    "## 9. Advanced Models I: LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant package\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "# Define X and y \n",
    "# X_variables = [''                 # ADJUST VARIABLES TO THOSE YOU WISH TO INCLUDE\n",
    "\n",
    "#               ]\n",
    "# y_variable = ''\n",
    "\n",
    "X_train = data_train.loc[:, X_variables]\n",
    "y_train = data_train[y_variable]\n",
    "X_test = data_test.loc[:, X_variables]\n",
    "y_test = data_test[y_variable]\n",
    "\n",
    "print(X_variables)\n",
    "\n",
    "# a) Set model parameters \n",
    "N_trees           = 100                           # Number of trees that are estimated\n",
    "Max_depth         = -1                            # Maximum depth of each tree (nr of levels); -1 means no limit\n",
    "Learning_rate     = 0.1                           # The learning rate ('eta')\n",
    "Min_child_samples = 10                            # Minimum number of items per bucket\n",
    "Min_child_weight  = 0.001                         # Minimum sum of instance weight (hessian) needed in a child (leaf).\n",
    "Subsample         = 1                             # Subsample ratio of the training instance\n",
    "Silent            = 1                             # Whether to print messages while running boosting\n",
    "Num_leaves        = 70                            # Maximum number of leafs per tree\n",
    "\n",
    "# Note: there are way more hyperparameters to tune. You can find them well-explained here: \n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "# The values above are not tuned and optimized yet\n",
    "\n",
    "# b) Estimate model\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "                         n_estimators=N_trees\n",
    "                        ,max_depth=Max_depth \n",
    "                        ,learning_rate=Learning_rate\n",
    "                        ,min_child_weight=Min_child_weight\n",
    "                        ,min_child_samples=Min_child_samples\n",
    "                        ,subsample=Subsample\n",
    "                        ,num_leaves=Num_leaves\n",
    "                        ,silent=Silent\n",
    "                       )\n",
    "\n",
    "lgb_model.fit(X_train, y_train)      # Fit the model over the train set\n",
    "\n",
    "# c) Create predictions for the test set\n",
    "preds_proba = lgb_model.predict_proba(X_test)\n",
    "preds = lgb_model.predict(X_test)   # Cut-off point equals 0.5\n",
    "\n",
    "#    Show the first 5 lines of the prediction probabilities and corresponding prediction\n",
    "#pd.concat([pd.DataFrame(preds_proba, columns=[\"Prob. 0\", \"Prob. 1\"]), pd.DataFrame(preds, columns=[\"Prediction\"])], axis=1).head()\n",
    "\n",
    "# d) Evaluate results\n",
    "#    i. Create confusion matrix\n",
    "#print(pd.crosstab(preds, y_test))\n",
    "\n",
    "#    ii. Create classification report\n",
    "#print(classification_report(y_test, preds))\n",
    "f1_lgb_model = f1_score(y_test, preds)\n",
    "\n",
    "#    iii. Get the feature importances of the lgb_modeloost\n",
    "importances = lgb_model.feature_importances_ \n",
    "std = np.std([lgb_model.feature_importances_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "importances_features = []\n",
    "print(\"Feature ranking:\")                    # Print the feature ranking\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"Feature %d (%s) %f\" % (indices[f], X_variables[indices[f]], importances[indices[f]]))\n",
    "    importances_features.append(X_variables[indices[f]])\n",
    "\n",
    "if False:\n",
    "    plt.figure(figsize=(7.5,5))\n",
    "    plt.figure()                                 # Plot the feature importances \n",
    "    plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.ylabel(\"Importance in terms of decreasing the weighted impurity\")\n",
    "    plt.xlabel(\"Feature\")\n",
    "    plt.xticks(range(X_train.shape[1]), importances_features, rotation = 30)\n",
    "    plt.xlim([-1, X_train.shape[1]])\n",
    "    plt.show()\n",
    "\n",
    "# Create ROC curve\n",
    "fpr, tpr, t = metrics.roc_curve(y_test, preds_proba[:,1])\n",
    "\n",
    "# Calculate AUC\n",
    "lgb_model_roc_auc_tree = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')      # Plot results\n",
    "plt.plot(fpr, tpr, lw=2, alpha=0.3, label='Mean ROC Decision Tree LightGBM (AUC = %0.2f)' % (lgb_model_roc_auc_tree))\n",
    "plt.title('ROC curve')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"10\"></a> \n",
    "\n",
    "\n",
    "## 10. Advanced Models II: CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant package\n",
    "import catboost as cat\n",
    "import time\n",
    "\n",
    "# Define X and y \n",
    "X_variables = [...]\n",
    "\n",
    "X_train = data_train.loc[:, X_variables]\n",
    "y_train = data_train[y_variable]\n",
    "X_test = data_test.loc[:, X_variables]\n",
    "y_test = data_test[y_variable]\n",
    "\n",
    "# Because we use CatBoost, we can leverage its abilitiy to handle categoricals in a clever way\n",
    "# For that, we need the column indices of the cat_features\n",
    "cat_features=[...]\n",
    "# Be aware: you might need to add the non-dummified columns to your dataset again, as those are dropped by default after set_dummies\n",
    "\n",
    "# a) Set model parameters \n",
    "N_trees        = ...                           # Number of trees that are estimated\n",
    "Max_depth      = ...                           # Maximum depth of each tree (nr of levels)\n",
    "Learning_rate  = ...                           # The learning rate ('eta')\n",
    "Subsample      = ...                           # Subsample ratio of the training instance\n",
    "Silent         = True                          # Whether to print messages while running boosting\n",
    "\n",
    "# Note: there are way more hyperparameters to tune. You can find them well-explained here: \n",
    "# https://catboost.ai/docs/concepts/parameter-tuning.html\n",
    "# The values above are not tuned and optimized yet\n",
    "\n",
    "# b) Estimate model\n",
    "cat_model = cat.CatBoostClassifier(\n",
    "                        n_estimators=N_trees\n",
    "                        ,max_depth=Max_depth \n",
    "                        ,learning_rate=Learning_rate\n",
    "                        ,subsample=Subsample\n",
    "                        ,silent=Silent\n",
    "                        ,cat_features=... \n",
    "                       )\n",
    "# You can uncomment the cat_features if you don't want to use this. \n",
    "# Given that we don't have many categories, this should not matter much. \n",
    "# But we leave it up to you to find out what the difference in speed and performance is!\n",
    "\n",
    "cat_model.fit(X_train, y_train)      # Fit the model over the train set\n",
    "\n",
    "# c) Create predictions for the test set\n",
    "preds_proba = cat_model.predict_proba(X_test)\n",
    "preds = cat_model.predict(X_test)   # Cut-off point equals 0.5\n",
    "\n",
    "#    Show the first 5 lines of the prediction probabilities and corresponding prediction\n",
    "#pd.concat([pd.DataFrame(preds_proba, columns=[\"Prob. 0\", \"Prob. 1\"]), pd.DataFrame(preds, columns=[\"Prediction\"])], axis=1).head()\n",
    "\n",
    "# d) Evaluate results\n",
    "#    i. Create confusion matrix\n",
    "#print(pd.crosstab(preds, y_test))\n",
    "\n",
    "#    ii. Create classification report\n",
    "#print(classification_report(y_test, preds))\n",
    "f1_cat_model = f1_score(y_test, preds)\n",
    "\n",
    "#    iii. Get the feature importances of the cat_modeloost\n",
    "importances = cat_model.feature_importances_ \n",
    "std = np.std([cat_model.feature_importances_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "importances_features = []\n",
    "print(\"Feature ranking:\")                    # Print the feature ranking\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"Feature %d (%s) %f\" % (indices[f], X_variables[indices[f]], importances[indices[f]]))\n",
    "    importances_features.append(X_variables[indices[f]])\n",
    "\n",
    "if False:\n",
    "    plt.figure(figsize=(7.5,5))\n",
    "    plt.figure()                                 # Plot the feature importances \n",
    "    plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.ylabel(\"Importance in terms of decreasing the weighted impurity\")\n",
    "    plt.xlabel(\"Feature\")\n",
    "    plt.xticks(range(X_train.shape[1]), importances_features, rotation = 30)\n",
    "    plt.xlim([-1, X_train.shape[1]])\n",
    "    plt.show()\n",
    "\n",
    "# Create ROC curve\n",
    "fpr, tpr, t = metrics.roc_curve(y_test, preds_proba[:,1])\n",
    "\n",
    "# Calculate AUC\n",
    "cat_model_roc_auc_tree = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')      # Plot results\n",
    "plt.plot(fpr, tpr, lw=2, alpha=0.3, label='Mean ROC Decision Tree CatBoost (AUC = %0.2f)' % (cat_model_roc_auc_tree))\n",
    "plt.title('ROC curve')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3202 - Churn- skeleton-easy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
